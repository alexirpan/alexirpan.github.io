---
layout: page
title: About
permalink: /about/
---

*Last updated January 8, 2025.*

I currently work as a Senior Research
Scientist on the AGI Safety and Alignment team at Google DeepMind.
The views expressed on this blog are
personal opinions, and do not reflect the opinions of my employer.

I'm somewhat new to directly working on alignment, so my exact work is going to
shift a lot as I figure out what parts of the problem I'm best at tackling.
(See [this post]({% post_url 2024-08-06-switching-to-ai-safety %}) if you're curious for why I decided to work on AI safety.)
In general, my research interests are deep reinforcement learning and agents.
Prior to working on safety, I did research in robotics, focusing on
the bottlenecks of robot learning in real-world problems. Common themes of that work
were more efficiently using real robot time, leveraging external data sources that
weren't bottlenecked on real robot hardware, and handling longterm agent-centric
data collection.

I graduated from the UC Berkeley Computer Science program in 2016, doing undergraduate
research in the [Berkeley Artificial Intelligence
Research (BAIR) Lab](http://bair.berkeley.edu/),
mentored by [Pieter Abbeel](http://www.cs.berkeley.edu/~pabbeel/) and
working most closely with [John Schulman](http://www.eecs.berkeley.edu/~joschu/).
I was an Honorable Mention for the NSF Graduate Research Fellowship
Program.

During my last year of undergrad, I was very unsure whether I wanted to keep doing
research, and eventually decided not to apply to PhD programs (a blog post I wrote
around that time can be seen [here]({% post_url 2016-01-03-grad-school %})).
However, I have an offer from the Google AI Residency Program, and decided I would
try this research thing for one more year.
I ended up liking ML research and have been at Google ever since.
A comparison of industry research versus
academia PhD can be seen [here]({% post_url 2021-04-07-grad-school-5years %}).

As someone who started in math, I've always had a soft spot for
theoretical computer science. Outside of machine learning, I enjoy
complexity theory, theoretical cryptography, and mathematical logic, although I'm
not as good at those subjects as I used to be.

This site doubles as my personal blog.
Posts range from discussion about machine learning to observations
of my life and stupid jokes. I post whenever I have the time and motivation to
do so, meaning not very often. Historically I average about one post per
month.

In my free time, I primarily play card games and video games.
My main games are Magic: the Gathering and Dominion. I've never been very good at MTG,
but at my peak I was top 20 worldwide at Dominion. (These days it's more like top 500.)

I'm a lapsed fan of *My Little Pony: Friendship is Magic*. "Lapsed" because, well,
it's complicated, [I have a post]({% post_url 2021-12-31-why-mlp %}) covering why. I keep up with
little of the fandom these days, but much of my music library is still made of [MLP or Touhou fan music](/recs).

My other main hobby is puzzlehunts. I've solved them for around 10 years, and I've helped
write multiple hunts, including MIT Mystery Hunt 2023. A list of puzzles
I've written is [here](/puzzles/).

If you're here for my blog, you're probably here for my
[post about why deep RL doesn't work]({% post_url 2018-02-14-rl-hard %}),
which is by far my most popular, but while you're visiting, why don't you read
my post about [the Neopets economy]({% post_url 2018-11-10-neopets-economy %})?

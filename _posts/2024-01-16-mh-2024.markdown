---
layout: post
title:  "MIT Mystery Hunt 2024"
date:   2022-01-19 20:23:00 -0700
---

*This has spoilers for MIT Mystery Hunt 2024. Spoilers are not labeled. I will try to add puzzle
links once there's a stable link to them.*

I often wait a bit to write about Mystery Hunt, but this year I'm quite busy in January so I'm going
to go before everything's fully static-fied.

Pre-Hunt
------------------------------------------

This year, I decided to get to Boston much earlier than usual. This was in-part because the company
I work for does limited vacation, which I'm bad at using. I needed to use some vacation to not
lose out on more, and what better time than Mystery Hunt? This made my Hunt much more relaxed than usual, since I got a few days to adjust to East Coast time and was able to schedule visits to Level99 and Boxaroo before Hunt.
We only went to Level99 because of [Dan Katz's post](https://puzzlvaria.wordpress.com/2023/09/12/challenge-frustration-and-balancing-user-expectations-level99-boda-borg-celeste-and-mao/)
on the subject. Let it be known that we had fun, I would recommend it too, and that post is fun to read
now that I know what some of the challenge rooms are. (My group also took a hint on Pirates Brig,
and had the same "yes, really do what you think we want you to do" reaction. I have three stars
because we figured out how to do it without much athleticism.)

As for Boxaroo, we had two groups doing two rooms, running a friendly contest on who could complete the rooms faster. The Boxaroo organizers knew we were doing this, so they:

* Invited mutual friends to spectate our attempts.
* Told us we were "3 minutes slower" when we did the second room, instead of our actual time.

When we compared notes afterwards, our total time for both rooms was within 20 seconds of the other group. I guess that's like not finding the coin by 10 minutes after the end of a long Mystery Hunt.

We also got shown a backstage tour of the room, due to finishing early. Some non-spoilery notes are that the room we did has dynamic extra puzzles depending on if you solve intermediate steps fast enough, and the room has a "wedding proposal mode".

Finally, we did Puzzled Pint, except, being silly people, we decided to make it more interesting by doing it "all brain". No writing implements allowed, and each puzzle must be solved serially before you
can do the next one. With 8 people, this *seemed* doable, but then the first puzzle was a nonogram, prompting a "OH NO IT'S SO OVER". We didn't solve the nonogram, but we did solve the puzzle, and eventually the entire set. Here's the puzzle from "Animal Casino" if you're curious.

IMAGE


Big Picture Thoughts
-----------------------------------------------------

Hunt went long again this year, although this time it was more because of puzzle count
than puzzle difficulty. If you were forced to pick how a Mystery Hunt runs long, I think most people would
pick the "too many puzzles" side of Mystery Hunt 2024 over the "too hard puzzles" side of Mystery
Hunt 2023.

Still, my preferred Hunt ending time is Sunday morning. On Saturday, TTBNL told our team captain that hunt was
projected to end Sunday evening, and while this was great for planning sleep, it did make me a bit worried we wouldn't
finish. After no "coin has been found" email came by Sunday 10 PM, I was *extra* concerned.
I ended up pulling almost an all-nighter on Sunday to try to push towards a finish, which we missed by two metas,
Sedona, AZ and Nashville, TN.

Running a Hunt with 237 puzzles is just...an insane number of puzzles. It's perfectly possible
to write such a Hunt that finishes on Sunday, if the difficulty was lower per puzzle. A quick estimate: in 2022,
Death & Mayhem was the first team to finish the Ministry, at [Friday 18:47 EST](https://puzzles.mit.edu/2022/stats/),
or 5.5 hours from puzzle release. The Investigation and the Ministry is approximately 40 puzzles. A very naive
linear extrapolation of (237 puzzles / 40 puzzles * 5.5 hours) gives a 33 hour finish time of Sunday 1 AM.
This goes to show that if you targeted that difficulty level, you could write 237 puzzles and still end on Sunday
assuming some overshooting on difficulty.

The issue is that you are really creating a harder problem for yourself than you need to. TTBNL was a big enough
team that I could see it working out, but in practice the difficulty trended up higher than the structure allowed.
The "fish" puzzles in Hole were a bit harder than I expected "fish" puzzles to be, and the killers
in this Hunt were just as hard as killers in other Mystery Hunts I've done. I still had a ton of fun, the majority
of puzzles I did were clean and had cool ideas, and the fraction of "meh" puzzles was no higher than previous
years. There was just a lot of them.

I really like that TTBNL did in-person interactions each Overworld meta, to the point that I think we
should have done so in 2023 and found a way to handle the logistics hell it would create. And when TTBNL decided
to give out free answers on each meta interaction, doing so with a "you need to use it now" caveat was a great way
to avoid the "teams stockpile free answers" problem we ran into during 2023. Between the events giving 2 free answers
instead of 1, and the gifted free answers, I believe we used around 15 free answers by the end of Hunt. It still does
not feel great to free answer your ways to metas, but it feels a little better when it's more gradual rather than
the team nuking a round at the end.


Thursday
------------------------------------------------------------------

I hunted with teammate again this year, because there is nothing quite like writing a Mystery Hunt to forge friends
through fire.

Instead of going straight to the team social, I stopped by the Mathcamp reunion, which I failed to go to last year
due to writing Hunt. I was very amused to see one group playing [Snatch](https://boardgamegeek.com/boardgame/9556/snatch)
and another group playing [Set](https://boardgamegeek.com/boardgame/1198/set), because these are *exactly* the
two games supported by teammate's Discord bot. I got back to the team social in time to play a custom Only Connect
game where I got flamed for losing a race to identify PINKIE PIE in a Missing Vowels round. I *knew the answer*.
My reaction time is *bad*. Gimme some slack.

We very definitely did not want to win this year (it wasn't even asked on the team survey), so we had a #losecomm
this year to figure out a way the most reasonable way to do so while still having fun.

The solution they arrived at was that no one was allowed to start or even look at a metapuzzle until all feeders
in the round had been forwardsolved. This could be overruled at the discretion of losecomm. For example, if the last feeder
was super stuck or grindy, we'd skip it for the sake of fun. We would also avoid using free answers. Otherwise, hints
and wild guesses were all fair game.

This policy is really more restrictive than it sounds, because the meta solvers on teammate
are pretty overpowered and solving at 70% of the feeders is often like getting to skip 50% of the work. It also implicitly
means no backsolving, because you'll never be in a position to do so.


Kickoff and Tech
-----------------------------------------------------------------------------

I enjoyed kickoff a lot. The flight safety health & safety video was excellent, and asking Mike Brown (author of
["How I Killed Pluto and Why It Had It Coming"](https://web.gps.caltech.edu/~mbrown/howikilled.html)) was a nice
touch. TTBNL has a number of Caltech people, so it makes sense they could do it, but it was still funny.

As we walk towards our classrooms, I try to login to the hunt site from my phone, and manage to do so once but see
a 500 error on a refresh. That's not a great sign. Once we get to our rooms, the 500 errors persist, and...now it is time for a tangent.

<div class="shaded" markdown="1">
## The Tech Rabbit Hole

Early in the hunt handoff period, TTBNL decided they wanted to use the 2023 hunt code, rather than prior years. We
cleaned it up, released it as the next iteration of [tph-site](https://github.com/teammatehunt/tph-site), and gave
advice during the year on debugging Docker errors, connecting the site, providing examples of interactive
puzzles, and so on. As Hunt got closer, the messages changed into how we handled email, webserver parameters, and size
of the machine used in Google Compute Engine. Most of our recommendations at this time are "use money to pay your way
out of problems, running a server for a weekend is not that expensive if you just want CPUs", and so they use a
48-core machine with similar parameters to us.

When the hunt site locks up and fails to recover, everyone who worked on tech infra for teammate starts suspecting
a database connection issue. This has been a persistent problem with tph-site's usage of websockets via
[Django Channels](https://channels.readthedocs.io/en/latest/), where it's super hungry on database
connections. We've never fully resolved this, but intuitively there's no way a site with a few thousand concurrent users
should need 600+ Postgres connections. It just...no, something smells wrong there on the math. It's caused issues for us
in the past, but we've worked around the issue via [connection pooling](https://stackoverflow.blog/2020/10/14/improve-database-performance-with-connection-pooling/)
and paying for larger servers.

We're pretty invested in getting Hunt fixed, so once it becomes clear this is not a normal hiccup, a few teammate people
drop into the handoff server to help debug with TTBNL.
There isn't too much we can do aside from passing along sample queries we used for diagnostics, asking questions about
server configuration, and recommending ways to reduce websocket load.

Over a few back and forths, we find that:

* TTBNL ran a load test before Hunt. The server worked, with an initial spike of delay that recovered later.
* The live server is behaving different from that load test. Instead of recovering, it becomes completely unresponsive. (!!)
* The typical locations that should contain error logs contain nothing (???!!!)
* CPU and RAM usage are high, but not near limits.
* The number of database connection is also high, but not near limits.

This makes debugging the issue really hard, since there are no logs, there is no reproduction of the error outside prod,
and the server isn't hitting any obvious bottlenecks. And so the best routes we can recommend to TTBNL are to just strip out
all non-essential Websockets and apply random changes to the database config until something works.

TTBNL will probably go into more detail in their AMA, but my rough understanding is that they figure out the request
queue is the reason the server crashes and stops responding, so they deploy a change that caps the queue size and force the server to
respond with 500s instead of stalling. (This is later explained as "fixing the server by making it fail faster".)
This makes the site slightly dodgy but also makes it actually stay up, and although the resource leak isn't root-caused,
the site is stable enough that it will keep working if it's restarted once an hour.

XKCD COMIC
{: .centered }

We got a very brief shout-out at wrap-up for helping fix the server. I don't think we actually did much besides moral support.

I've been poking into tph-site post-hunt, and I still don't
understand why the load test pre-Hunt failed to capture the during Hunt behavior. Maybe the extra Hunt participants pushed things over the edge? Maybe
a team's hunt management software hammered the backend too hard? Maybe MIT Guest Wi-Fi does something weird? I know
I kept seeing intermittent "Blocked Page" errors on their network when I tried to Google search on Firefox, and needing to use an incognito window
to fix it.

Still, I suspect that this is a problem that is better cut at the source. By now, both GPH 2022 and Mystery Hunt have had
server issues tied to websockets via Django Channels. There is definitely a way to make it work (I've found claims of scaling
Channels to millions of users), but, there is something fishy going on there.

Of the websocket heavy puzzlehunts, the Projection Device used a Go backend IIRC, and Galactic [entirely rewrote their backend for GalactiCardCaptors](https://2023.galacticpuzzlehunt.com/wrapup) to avoid Channels because they lost trust in its scaling. I think the platonic ideal hunt server would do the
same and stop using Channels, but I'm not sure the migration work would be worth it.
[Silenda](https://github.com/YewLabs/silenda) from Mystery Hunt 2021 used Django Channels.
So does [Spoilr](https://github.com/Palindrome-Puzzles/2022-hunt) from Mystery Hunt 2022 and [tph-site](https://github.com/teammatehunt/tph-site)
from Mystery Hunt 2023. Real companies have made Django Channels work for them, and this might be a case of
preferring the devil that's already implemented over the one that's not.
</div>


Hunt! (Friday)
-----------------------------------------------------------------------------

With the site fixed, it's time to get into the puzzles proper.

## The Throne Room

**Herc-U-Lease** - Ah, the scavenger hunt! Technically not in this round but I'll put it here since
I barely touched anything in this round (aside from gruntwork clues in Annual International Fictionary Night).

We started doing this, but did a cost-benefit analysis and decided the effort
needed to get enough drachma was too high. By the time the nerf came in Saturday, we had a lot of open puzzles and the cost-benefit
still seemed too small.

Looking at past Mystery Hunts, the [2022 scav hunt](https://puzzles.mit.edu/2022/round/the-ministry/book-reports/) maxed out at 100 points, with 10 points for the hardest tasks.
The [2023 scav hunt](https://puzzles.mit.edu/2023/puzzlefactory.place/puzzles/touch-grass-challenge-impossible) maxed out at 90 points, with 30 points for the hardest tasks, although I'm guessing most teams did the 10-15 point tasks. That's around 10 hard tasks for both hunts if you're on a big team.
The 2024 scav hunt maxed out at 60 drachma and gave 3 drachma for the hardest tasks, or 20 hard tasks, twice as many.
Even post nerf to 45 drachma, it was still longer than recent scavenger hunts. Given that the goal of scavenger hunts is to
get teams to do goofy things, I'd err on the side of easier and would recommend future teams target 10 hard tasks per Hunt
as their maximum.

I'll still include our video for "throw something through 12 rings, each held by a different person", because it never saw
the light of day. The people coordinating scav hunt asked the room to take 1 minute to help them do a task. To make it easier, we put
all the rings close to one another, but the person holding the last ring didn't have anywhere to stand except for right in front of the rings.
Holding the last ring, he said "sure, I'm ready to get hit by something" right before the most predictable thing happened.

VIDEO


## The Underworld Court

This round was released via Google Docs to teams, using phone callbacks.
I don't really miss them but it was a fun throwback.

**Badges Badges Badges** - The first puzzle I worked on while waiting for puzzle release. Honestly I'm surprised this is the first time someone made
the nametags a puzzle, but they *have* only been a thing for 3 years. I quickly recognize mine is NATO, but by the
time I figure out what "echo" is, someone else has already solved the full badge. Then I get sidetracked into tech debugging and stop paying attention to this puzzle.

**Roguelikes with a K** - Listen, I'm always down to try a roguelike. I quickly learn I'm bad at
roguelikes relative to teammate, and busy myself with organizing the sheet instead. We submit (well, call-in) what we think is the final answer, but realize the next step before TTBNL calls us back.
I still have objections to some of the interpretations, they felt a bit loose. We considered Wordle to have resource management, since you had a limited number of guesses, but figured out it needed to be "false" during our error correction tweaking. Overall, cool idea, just wish it was tighter.

**Dating Stars** - By the time I got to the puzzle, they had figured out the Chinese zodiac a-ha, but not anything else. In a desperate attempt to fit the Western zodiac, I was asked to check if anything might be
related to Homestuck. I read over the puzzle and said "definitely not, also why did you think of Homestuck???" They broke-in after I left.

**Judges of the Underworld (meta)** - We broke in on the mechanic pretty much immediately, and having all the answers was definitely not helpful. Two of us (including me) were convinced that the heights of the pillars on the round page would be important for ordering, and got confused why it was reading so poorly, right up until someone resorted the sheet.

## Rivers of the Dead

**Why the Romans Never Invented Logic Puzzle** - This idea was both cursed and a lot of fun. Three of us were working on a grid, slowly making deductions and trying to fix our mistakes when we hit a contradiction, and then Lumia says "okay, I've solved the logic puzzle" and drops the completed grid into the sheet.
This is common enough that I've stopped questioning it.

Initially, the large fractions of Js in the cluephrase makes me think we need to filter it with the Latin alphabet (i.e. there are no Js in Latin so ignore all Js). This doesn't work, but I eventually decide that it really ought to be a do-it-again, spot the matching strings, and help solve it from there.
After finding it harder than expected, I get tempted to write a Python brute force script instead. By the time I finish typing up the Roman numeral constants, the puzzle's been solved.

**Two Outs, Two Strikes, and...** - I didn't solve this puzzle, just here to say it was pretty funny..

**temporary name** - We solve the answer to puzzle matching pretty quickly, and I volunteer to enter it into the site. It fails to do anything, and I say we need to do something else. Later, someone else tries our answers and it works, unlocking part 2. Oops guess I filled out the form wrong.

The policy also died by Saturday morning. I'm told that TTBNL visited us, losecomm asked where we were in the leaderboard,
and learned we were outside the top 10. That prompted an "oh shit we might not finish" and we pulled off all the brakes
throuh Saturday, Sunday, and Monday. I think I still did not try-hard as much as I could have - it took me a while to look
at metas and I didn't even try to backsolve anything this Mystery Hunt, but I've heard most of the Overworld metas were hard to backsolve anyays.

